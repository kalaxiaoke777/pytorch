{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-10T08:14:30.597236Z",
     "start_time": "2025-04-10T08:14:30.592199Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "from numpy.lib.utils import source\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:14:30.647998Z",
     "start_time": "2025-04-10T08:14:30.600806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, dropout=0.1):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.embedding(x))"
   ],
   "id": "22a5a2f1a8ae8358",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:14:30.681855Z",
     "start_time": "2025-04-10T08:14:30.672530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab_size = 16\n",
    "embed_size = 512\n",
    "input = torch.LongTensor([[1,3,4,5],[2,4,5,6],[3,5,6,7]])\n",
    "embedding = Embedding(vocab_size,embed_size)\n",
    "embedding_res = embedding(input)\n",
    "embedding_res.shape"
   ],
   "id": "1009b88801e6ee1b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 512])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:14:30.723757Z",
     "start_time": "2025-04-10T08:14:30.714758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        self.pe = torch.zeros(max_len, d_model)\n",
    "\n",
    "\n",
    "        positions = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "\n",
    "        self.pe[:, 0::2] = torch.sin(positions * div_term)\n",
    "        self.pe[:, 1::2] = torch.cos(positions * div_term)\n",
    "\n",
    "\n",
    "        self.pe = self.pe.unsqueeze(0)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], requires_grad=False)\n",
    "        return self.dropout(x)"
   ],
   "id": "e2caa8529be3219a",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:14:30.779013Z",
     "start_time": "2025-04-10T08:14:30.758861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "d_model = 512\n",
    "positionalEncoding = PositionalEncoding(d_model)\n",
    "pe_res = positionalEncoding(embedding_res)\n",
    "query = key = value = pe_res"
   ],
   "id": "ac8acafe59de949d",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:14:30.826806Z",
     "start_time": "2025-04-10T08:14:30.809278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "\n",
    "    d_k = query.size(1)\n",
    "    source = torch.matmul(query, key.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        source = source.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "    att = F.softmax(source, dim=-1)\n",
    "\n",
    "    if dropout is not None:\n",
    "        att = dropout(att)\n",
    "\n",
    "    return torch.matmul(att, value)\n",
    "\n",
    "def clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, head, embed_size, dropout=0.1):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.head = head\n",
    "        self.embed_size = embed_size\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        assert d_model % head == 0\n",
    "        self.d_k = embed_size // head\n",
    "\n",
    "        self.linear = clones(nn.Linear(embed_size, embed_size), 4)\n",
    "    def forward(self, query, key, value, mask=None, dropout=None):\n",
    "\n",
    "        batch_size = query.size(0)\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(0)\n",
    "        query, key, value = [model(x).view(batch_size,-1,self.head,self.d_k).transpose(1,2) for model, x in zip(self.linear,(query, key, value))]\n",
    "\n",
    "        x = attention(query, key, value, mask=mask, dropout=dropout)\n",
    "        x = x.transpose(1,2).contiguous().view(batch_size, -1, self.head*self.d_k)\n",
    "\n",
    "        return self.linear[-1](x)\n",
    "head = 8\n",
    "embed_size = 512\n",
    "multiHeadAttention = MultiHeadAttention(head, embed_size, dropout=0.1)\n",
    "mask = torch.zeros([8,4,4])\n",
    "x = multiHeadAttention(query, key, value, mask)"
   ],
   "id": "f52b3ce4a7e308ca",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:14:30.890227Z",
     "start_time": "2025-04-10T08:14:30.883171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        x = self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "        return x"
   ],
   "id": "3ef1be401e6c5914",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:14:30.959037Z",
     "start_time": "2025-04-10T08:14:30.933688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "positionwiseFeedForward = PositionwiseFeedForward(512,512*4,dropout=0.1)\n",
    "x = positionwiseFeedForward(x)"
   ],
   "id": "ef7ed31ab4b18d29",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:14:30.977906Z",
     "start_time": "2025-04-10T08:14:30.969013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = nn.LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ],
   "id": "fea77722eeee41ee",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:14:31.028365Z",
     "start_time": "2025-04-10T08:14:31.016790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # 这里是将位置编码结果和注意力进行残差连接\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        # 然后再残差连接至前馈神经层\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ],
   "id": "9db0f95a805662be",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:14:31.073561Z",
     "start_time": "2025-04-10T08:14:31.067013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = nn.LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            # 这里会进行n次连接\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ],
   "id": "d36cd030a1dc2a05",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T08:15:35.753785Z",
     "start_time": "2025-04-10T08:15:35.605250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, d_model, d_ff, head, N, dropout=0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.embedding = Embedding(vocab_size, embed_size, dropout)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout)\n",
    "        self.encoder = Encoder(\n",
    "            EncoderLayer(\n",
    "                size=d_model,\n",
    "                self_attn=MultiHeadAttention(head, d_model, dropout),\n",
    "                feed_forward=PositionwiseFeedForward(d_model, d_ff, dropout),\n",
    "                dropout=dropout\n",
    "            ),\n",
    "            N\n",
    "        )\n",
    "\n",
    "    def forward(self, src, mask):\n",
    "        x = self.embedding(src)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.encoder(x, mask)\n",
    "        return x\n",
    "\n",
    "vocab_size = 16\n",
    "embed_size = 512\n",
    "d_model = 512\n",
    "d_ff = 2048\n",
    "head = 8\n",
    "N = 6  # 编码器层数\n",
    "def make_mask(src, pad_token=0):\n",
    "    mask = (src != pad_token).unsqueeze(-2)\n",
    "    return mask\n",
    "model = TransformerEncoder(vocab_size, embed_size, d_model, d_ff, head, N)\n",
    "\n",
    "src = torch.LongTensor([[1, 3, 4, 5], [2, 4, 5, 6], [3, 5, 6, 7]])\n",
    "mask = torch.zeros([8, 4, 4])\n",
    "output = model(src, mask)\n",
    "output.size(),output.shape"
   ],
   "id": "405cf8bef2a309d5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4, 512]), torch.Size([3, 4, 512]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
