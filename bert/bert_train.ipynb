{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-24T07:47:45.936964Z",
     "start_time": "2025-04-24T07:47:45.895031Z"
    }
   },
   "source": [
    "# coding: UTF-8\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from transformers import BertModel, BertTokenizer, BertConfig\n",
    "# coding: UTF-8\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from utils import get_time_dif\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import logging\n",
    "\n",
    "\n",
    "class Config(object):\n",
    "    def __init__(self, dataset):\n",
    "        self.model_name = \"bert\"\n",
    "        self.data_path = \"/home/ec2-user/toutiao/data/data/\"\n",
    "        self.train_path = self.data_path + \"train.txt\"  # 训练集\n",
    "        self.dev_path = self.data_path + \"dev.txt\"  # 验证集\n",
    "        self.test_path = self.data_path + \"test.txt\"  # 测试集\n",
    "        self.class_list = [\n",
    "            x.strip() for x in open(self.data_path + \"class.txt\").readlines()\n",
    "        ]  # 类别名单\n",
    "        self.save_path = '/home/ec2-user/toutiao/src/saved_dict'\n",
    "        if not os.path.exists(self.save_path):\n",
    "            os.mkdir(self.save_path)\n",
    "        self.save_path += \"/\" + self.model_name + \".pt\"  # 模型训练结果\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 设备\n",
    "\n",
    "        self.require_improvement = 1000  # 若超过1000batch效果还没提升，则提前结束训练\n",
    "        self.num_classes = len(self.class_list)  # 类别数\n",
    "        self.num_epochs = 3  # epoch数\n",
    "        self.batch_size = 128  # mini-batch大小\n",
    "        self.pad_size = 32  # 每句话处理成的长度(短填长切)\n",
    "        self.learning_rate = 5e-5  # 学习率\n",
    "        self.bert_path = \"/home/ec2-user/toutiao/data/bert_pretrain\"\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.bert_path)\n",
    "        self.bert_config = BertConfig.from_pretrained(self.bert_path + '/bert_config.json')\n",
    "        self.hidden_size = 768\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Model, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(config.bert_path, config=config.bert_config)\n",
    "\n",
    "        self.fc = nn.Linear(config.hidden_size, config.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入的句子\n",
    "        context = x[0]\n",
    "        # 对padding部分进行mask, 和句子一个size, padding部分用0表示, 比如[1, 1, 1, 1, 0, 0]\n",
    "        mask = x[2]\n",
    "\n",
    "        _, pooled = self.bert(context, attention_mask=mask)\n",
    "        out = self.fc(pooled)\n",
    "\n",
    "        return out\n",
    "def loss_fn(outputs, labels):\n",
    "    return nn.CrossEntropyLoss()(outputs, labels)\n",
    "\n",
    "\n",
    "def train(config, model, train_iter, dev_iter):\n",
    "    start_time = time.time()\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.01\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0\n",
    "        }]\n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=config.learning_rate)\n",
    "    total_batch = 0  # 记录进行到多少batch\n",
    "    dev_best_loss = float(\"inf\")\n",
    "    last_improve = 0  # 记录上次验证集loss下降的batch数\n",
    "    flag = False  # 记录是否很久没有效果提升\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(config.num_epochs):\n",
    "        total_batch = 0\n",
    "        print(\"Epoch [{}/{}]\".format(epoch + 1, config.num_epochs))\n",
    "        for i, (trains, labels) in enumerate(tqdm(train_iter)):\n",
    "            outputs = model(trains)\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if total_batch % 200 == 0 and total_batch != 0:\n",
    "                # 每多少轮输出在训练集和验证集上的效果\n",
    "                true = labels.data.cpu()\n",
    "                predic = torch.max(outputs.data, 1)[1].cpu()\n",
    "                train_acc = metrics.accuracy_score(true, predic)\n",
    "                dev_acc, dev_loss = evaluate(config, model, dev_iter)\n",
    "                if dev_loss < dev_best_loss:\n",
    "                    dev_best_loss = dev_loss\n",
    "                    torch.save(model.state_dict(), config.save_path)\n",
    "                    improve = \"*\"\n",
    "                    last_improve = total_batch\n",
    "                else:\n",
    "                    improve = \"\"\n",
    "                time_dif = get_time_dif(start_time)\n",
    "                msg = \"Iter: {0:>6},  Train Loss: {1:>5.2},  Train Acc: {2:>6.2%},  Val Loss: {3:>5.2},  Val Acc: {4:>6.2%},  Time: {5} {6}\"\n",
    "                print(msg.format(total_batch, loss.item(), train_acc, dev_loss, dev_acc, time_dif, improve))\n",
    "                # 评估完成后将模型置于训练模式, 更新参数\n",
    "                model.train()\n",
    "\n",
    "            # 每个batch结束后累加计数\n",
    "            total_batch += 1\n",
    "\n",
    "            if total_batch - last_improve > config.require_improvement:\n",
    "                # 验证集loss超过1000batch没下降，结束训练\n",
    "                print(\"No optimization for a long time, auto-stopping...\")\n",
    "                flag = True\n",
    "                break\n",
    "        if flag:\n",
    "            break\n",
    "def test(config, model, test_iter):\n",
    "    # model.load_state_dict(torch.load(config.save_path))\n",
    "    # 采用量化模型进行推理时需要关闭\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    test_acc, test_loss, test_report, test_confusion = evaluate(config, model, test_iter, test=True)\n",
    "\n",
    "    msg = \"Test Loss: {0:>5.2},  Test Acc: {1:>6.2%}\"\n",
    "    print(msg.format(test_loss, test_acc))\n",
    "    print(\"Precision, Recall and F1-Score...\")\n",
    "    print(test_report)\n",
    "    print(\"Confusion Matrix...\")\n",
    "    print(test_confusion)\n",
    "    time_dif = get_time_dif(start_time)\n",
    "    print(\"Time usage:\", time_dif)\n",
    "def evaluate(config, model, data_iter, test=False):\n",
    "    # 采用量化模型进行推理时需要关闭\n",
    "    model.eval()\n",
    "    loss_total = 0\n",
    "    predict_all = np.array([], dtype=int)\n",
    "    labels_all = np.array([], dtype=int)\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in data_iter:\n",
    "            outputs = model(texts)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "            loss_total += loss\n",
    "            labels = labels.data.cpu().numpy()\n",
    "            predic = torch.max(outputs.data, 1)[1].cpu().numpy()\n",
    "            labels_all = np.append(labels_all, labels)\n",
    "            predict_all = np.append(predict_all, predic)\n",
    "\n",
    "    acc = metrics.accuracy_score(labels_all, predict_all)\n",
    "    if test:\n",
    "        report = metrics.classification_report(labels_all,predict_all,target_names=config.class_list,digits=4)\n",
    "        confusion = metrics.confusion_matrix(labels_all, predict_all)\n",
    "        return acc, loss_total / len(data_iter), report, confusion\n",
    "    return acc, loss_total / len(data_iter)\n",
    "\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from train_eval import train, test\n",
    "from importlib import import_module\n",
    "import argparse\n",
    "from utils import build_dataset, build_iterator, get_time_dif\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Chinese Text Classification\")\n",
    "parser.add_argument(\"--model\", type=str, required=True, help=\"choose a model: bert\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = \"toutiao\"  # 数据集\n",
    "    if args.model == \"bert\":\n",
    "        model_name = \"bert\"\n",
    "        x = import_module(\"models.\" + model_name)\n",
    "        config = x.Config(dataset)\n",
    "        np.random.seed(1)\n",
    "        torch.manual_seed(1)\n",
    "        torch.cuda.manual_seed_all(1)\n",
    "        torch.backends.cudnn.deterministic = True  # 保证每次结果一样\n",
    "\n",
    "        print(\"Loading data for Bert Model...\")\n",
    "        train_data, dev_data, test_data = build_dataset(config)\n",
    "        train_iter = build_iterator(train_data, config)\n",
    "        dev_iter = build_iterator(dev_data, config)\n",
    "        test_iter = build_iterator(test_data, config)\n",
    "\n",
    "        model = x.Model(config).to(config.device)\n",
    "        train(config, model, train_iter, dev_iter)\n",
    "        test(config,model, test_iter)"
   ],
   "outputs": [],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
